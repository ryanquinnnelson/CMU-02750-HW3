{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF, WhiteKernel,ExpSineSquared,DotProduct,RationalQuadratic\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from modAL.models import BayesianOptimizer, ActiveLearner, CommitteeRegressor\n",
    "from modAL.acquisition import max_EI\n",
    "from modAL.disagreement import max_std_sampling\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "# import seqlogo\n",
    "\n",
    "import copy\n",
    "\n",
    "### Set random seed\n",
    "seed = 5\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "### Suppresses Warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Data Load (5 points)\n",
    "**In this question, you need to build a regression model with active learning for predicting binding affinity between MHC class I and small peptides. The dataset is provided in file `hw3_data.csv`.**\n",
    "\n",
    "**TODO**\n",
    "- **Read the data into the jupyter notebook. Columns 2 and 3 in the dataset file correspond to peptide sequences and pIC50 values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9051, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allele</th>\n",
       "      <th>seq</th>\n",
       "      <th>pIC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seq0</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>AIIDYIAYM</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seq1</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>AIYDTMQYV</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seq2</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>ALATFTVNI</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seq3</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>ALDEGLLPV</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seq4</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>ALFPIIWAL</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       allele        seq  pIC50\n",
       "0  seq0  HLA-A*02:01  AIIDYIAYM    9.0\n",
       "1  seq1  HLA-A*02:01  AIYDTMQYV    9.0\n",
       "2  seq2  HLA-A*02:01  ALATFTVNI    9.0\n",
       "3  seq3  HLA-A*02:01  ALDEGLLPV    9.0\n",
       "4  seq4  HLA-A*02:01  ALFPIIWAL    9.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/hw3_data.csv', delimiter=',',header=0)\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Encode Data (10 points)\n",
    "**Since we are dealing with machine learning models, you need to convert peptide sequences into feature vectors. The simplest way to do this is to use a one-hot encoding.**\n",
    "\n",
    "**Each character in the amino acid alphabet will correspond to a binary vector with a single 1 and all zeros. The size of the vector is equal to the size of the amino acid alphabet. The position of 1 encodes a specific amino acid. The resulting feature vector for a peptide is a concatenation of the feature vectors of its amino acids. Since we are dealing with 9-mers here, the size of the feature vector for a peptide should be equal to 9*(size of the amino acid alphabet).**\n",
    "\n",
    "**TODO**\n",
    "- **Encode the data.**\n",
    "- **Split data into train and test datasets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Data\n",
    "I want to keep some notion of the order of the amino acids. The 3D structure they form is vital for predicting binding quality. One possible way is to group letters in order. How do I decide how many letters constitutes a group?\n",
    "\n",
    "Ex: 3-mers\n",
    "```\n",
    "AIIDYIAYM\n",
    "AII\n",
    " IID\n",
    "  IDY\n",
    "    ...\n",
    "      AYM\n",
    "```\n",
    "\n",
    "3-mers results in N < J, where N is the number of samples and J is the number of features. If we want to use multivariate regression, we'll need to use ridge regression or some other sparse form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['seq'].str.len().unique()  # every seq is length 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate columns for each amino acid\n",
    "for i in range(9):\n",
    "    colname='seq'+str(i)\n",
    "    data[colname] = [x[i] for x in data['seq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allele</th>\n",
       "      <th>seq</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>seq0</th>\n",
       "      <th>seq1</th>\n",
       "      <th>seq2</th>\n",
       "      <th>seq3</th>\n",
       "      <th>seq4</th>\n",
       "      <th>seq5</th>\n",
       "      <th>seq6</th>\n",
       "      <th>seq7</th>\n",
       "      <th>seq8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seq0</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>AIIDYIAYM</td>\n",
       "      <td>9.0</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>D</td>\n",
       "      <td>Y</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       allele        seq  pIC50 seq0 seq1 seq2 seq3 seq4 seq5 seq6  \\\n",
       "0  seq0  HLA-A*02:01  AIIDYIAYM    9.0    A    I    I    D    Y    I    A   \n",
       "\n",
       "  seq7 seq8  \n",
       "0    Y    M  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique letters\n",
    "len(data['seq0'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create triplets\n",
    "# k = 3\n",
    "# count = 9-k+1\n",
    "# start=0\n",
    "# end=k\n",
    "# for i in range(count):\n",
    "#     colname='triplet'+str(i)\n",
    "#     data[colname] = [x[start:end] for x in data['seq']]\n",
    "#     start +=1\n",
    "#     end +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allele</th>\n",
       "      <th>seq</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>seq0</th>\n",
       "      <th>seq1</th>\n",
       "      <th>seq2</th>\n",
       "      <th>seq3</th>\n",
       "      <th>seq4</th>\n",
       "      <th>seq5</th>\n",
       "      <th>seq6</th>\n",
       "      <th>seq7</th>\n",
       "      <th>seq8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seq0</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>AIIDYIAYM</td>\n",
       "      <td>9.0</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>D</td>\n",
       "      <td>Y</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       allele        seq  pIC50 seq0 seq1 seq2 seq3 seq4 seq5 seq6  \\\n",
       "0  seq0  HLA-A*02:01  AIIDYIAYM    9.0    A    I    I    D    Y    I    A   \n",
       "\n",
       "  seq7 seq8  \n",
       "0    Y    M  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9051, 9)\n",
      "(9051,)\n"
     ]
    }
   ],
   "source": [
    "X_df = data.drop(['pIC50','id','allele', 'seq'],axis=1)\n",
    "y = data['pIC50']\n",
    "print(X_df.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq0</th>\n",
       "      <th>seq1</th>\n",
       "      <th>seq2</th>\n",
       "      <th>seq3</th>\n",
       "      <th>seq4</th>\n",
       "      <th>seq5</th>\n",
       "      <th>seq6</th>\n",
       "      <th>seq7</th>\n",
       "      <th>seq8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>D</td>\n",
       "      <td>Y</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seq0 seq1 seq2 seq3 seq4 seq5 seq6 seq7 seq8\n",
       "0    A    I    I    D    Y    I    A    Y    M"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(9051, 180)\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X_enc = enc.fit_transform(X_df)\n",
    "print(type(X_enc))\n",
    "print(X_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(9051, 180)\n",
      "(9051,)\n"
     ]
    }
   ],
   "source": [
    "# convert to numpy array\n",
    "X_pool=sparse.csr_matrix.toarray(X_enc)\n",
    "print(type(X_pool))\n",
    "print(X_pool.shape)\n",
    "y_pool = y.to_numpy()\n",
    "print(y_pool.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "- ~~X_initial: set of samples removed from data pool for initialization~~\n",
    "- X_train: 2/3 of data pool\n",
    "- X_test: 1/3 of data pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(6064, 180)\n",
      "(6064,)\n",
      "(2987, 180)\n",
      "(2987,)\n"
     ]
    }
   ],
   "source": [
    "#?? initial training set for active learners?\n",
    "# n_initial = 10\n",
    "\n",
    "# # select random instances to use as initial active learning training set\n",
    "# idx_initial = np.random.choice(X_np.shape[0], n_initial)\n",
    "# X_initial = X_np[idx_initial]\n",
    "# y_initial = y_np[idx_initial]\n",
    "# print(X_initial.shape)\n",
    "# print(y_initial.shape)\n",
    "\n",
    "\n",
    "# # remove from pool of data for testing and training\n",
    "# X_pool = np.delete(X_np, idx_initial, axis=0)\n",
    "# y_pool = np.delete(y_np, idx_initial, axis=0)\n",
    "# print(X_pool.shape)\n",
    "# print(y_pool.shape)\n",
    "\n",
    "\n",
    "# split remaining pool of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pool, y_pool, test_size=0.33)\n",
    "print()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with offline learners and kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4769976135583013\n",
      "CPU times: user 420 ms, sys: 11.3 ms, total: 431 ms\n",
      "Wall time: 443 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train RFC model on entire pool of data\n",
    "rf = RandomForestRegressor(n_estimators = 20, \n",
    "                            max_depth = 6, \n",
    "                            random_state = seed)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "print(rf.score(X_test,y_test))  # uses R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6323258584401178\n",
      "CPU times: user 24.8 ms, sys: 2.34 ms, total: 27.1 ms\n",
      "Wall time: 9.7 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# clf = Ridge(alpha=1.0)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print(clf.score(X_test,y_test))  #0.632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search had no significant improvement \n",
    "# for i in np.linspace(0.1,5,50):\n",
    "#     clf = Ridge(alpha=i)\n",
    "#     clf.fit(X_train, y_train)\n",
    "\n",
    "#     print(np.round(i,2),np.round(clf.score(X_test,y_test),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6864150454910358\n",
      "CPU times: user 14min 49s, sys: 60 s, total: 15min 49s\n",
      "Wall time: 8min 9s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # 15 minutes for (5931,180)\n",
    "\n",
    "# check if WhiteKernel helps or not\n",
    "# kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) \\\n",
    "#          + WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e+1))\n",
    "\n",
    "# gpr = GaussianProcessRegressor(kernel,random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test)) #0.686 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6885491476785116\n",
      "CPU times: user 3min 46s, sys: 9.89 s, total: 3min 56s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# #2 min\n",
    "\n",
    "# # checking if WhiteKernel is helping or not\n",
    "# kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3))\n",
    "\n",
    "# gpr = GaussianProcessRegressor(kernel,random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test)) #0.6885"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6885491475209322\n",
      "CPU times: user 4min 25s, sys: 11.2 s, total: 4min 36s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # 2 min\n",
    "\n",
    "# # checking if bounds is helping or not\n",
    "# kernel = RBF(length_scale=1.0)\n",
    "\n",
    "# gpr = GaussianProcessRegressor(kernel,random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test))  #0.6885"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6888081881838393\n",
      "CPU times: user 6min 2s, sys: 24.8 s, total: 6min 27s\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # 3.5 min\n",
    "\n",
    "# kernel = RationalQuadratic(length_scale=1.0, alpha=1.5, length_scale_bounds=(1e-2, 1e3))\n",
    "# gpr = GaussianProcessRegressor(kernel,random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test)) #0.6888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6322700927884628\n",
      "CPU times: user 4min 59s, sys: 20.1 s, total: 5min 19s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # 2 min\n",
    "\n",
    "# kernel = DotProduct() + WhiteKernel()\n",
    "# gpr = GaussianProcessRegressor(kernel,random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test)) # 0.632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8066693577258328\n",
      "CPU times: user 21.4 s, sys: 1.2 s, total: 22.6 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # 15 s\n",
    "\n",
    "# gpr = GaussianProcessRegressor(random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test)) # -0.806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # can't overcome the linear algebra error\n",
    "# # local periodic - add\n",
    "\n",
    "# kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) + ExpSineSquared(length_scale=1, periodicity=1)\n",
    "\n",
    "# for alpha in [1E-9,1E-8,1E-7,1E-6,1E-5,1E-4,1E-3,1E-2,1E-1,1E-0]:\n",
    "        \n",
    "# #     try:\n",
    "# #         gpr = GaussianProcessRegressor(kernel,random_state=seed, alpha=alpha)\n",
    "# #         gpr.fit(X_train, y_train)\n",
    "# #         print(alpha, gpr.score(X_test,y_test))  \n",
    "# #     except LinAlgError:\n",
    "# #         print(alpha, \"Error\")\n",
    "# #         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = RBF(length_scale=0.45,length_scale_bounds=(1e-2, 1e3)) + WhiteKernel(noise_level=1.0, noise_level_bounds=(1e-10, 1e+1))\n",
    "a[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Build Active Learning  model (20 points)\n",
    "**Now you can start building the model with active learning! We do not give you any specific instructions as to which algorithm to implement. You can use something similar to [this](https://modal-python.readthedocs.io/en/latest/content/examples/active_regression.html) example in modAL documentation, or query-by-committee when a label is requested for samples which the committee is least confident about or anything else covered in the lectures.**\n",
    "\n",
    "**TODO**\n",
    "- **Implement an active learning algorithm using modAL.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?? Cookbook suggests \"put a product of SE kernels on those dimensions\" (I have 180 dimensions)\n",
    "#?? not remove from pool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_sample(learner, X, y):\n",
    "    \n",
    "    # call the query strategy defined in the learner to obtain a new sample\n",
    "    query_idx, query_sample = learner.query(X)\n",
    "    \n",
    "    # modify indexing to interpret as collection of one element with d features\n",
    "    query_sample_reshaped = query_sample.reshape(1,-1)\n",
    "   \n",
    "    # obtain the query label\n",
    "    query_label = y[query_idx]\n",
    "\n",
    "    # modify indexing to interpret as 1D array of one element\n",
    "    query_label_reshaped = query_label.reshape(1,)\n",
    "    \n",
    "    return query_sample_reshaped, query_label_reshaped, query_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_active_learner_regression(learner, X_pool, y_pool, X_test, y_test, n_queries):\n",
    "\n",
    "#     history = [] # score history\n",
    "    \n",
    "#     # score model before active learning starts\n",
    "#     y_pred = learner.predict(X_test, return_std=False)\n",
    "#     history.append(r2_score(y_test,y_pred))  # y_true,y_pred\n",
    "\n",
    "    # perform active learning\n",
    "    for q in range(n_queries):\n",
    "\n",
    "        # get sample\n",
    "        X_sample, y_sample, query_idx = get_next_sample(learner, X_pool, y_pool)\n",
    "\n",
    "        # use new sample to update the model\n",
    "        learner.teach(X_sample, y_sample)\n",
    "\n",
    "#         # score current model\n",
    "#         y_pred = learner.predict(X_test, return_std=False)\n",
    "#         history.append(r2_score(y_test,y_pred))\n",
    "        \n",
    "        # remove labeled instance from pool\n",
    "        X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, query_idx)\n",
    "        \n",
    "#     return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_to_file(filename,fields,rows):\n",
    "    \n",
    "    with open(filename,'a') as f:\n",
    "        \n",
    "        # using csv.writer method from CSV package \n",
    "        write = csv.writer(f) \n",
    "\n",
    "        write.writerow(fields) \n",
    "        write.writerows(rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [1,2,3]\n",
    "fields = ['a','b','c']\n",
    "write_results_to_file('data/test.csv', fields, rows)\n",
    "rows = [1,2,4]\n",
    "write_results_to_file('data/test.csv', fields, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_process_regressor_gs(kernels, n_learners, n_initials, X_pool, y_pool, X_test, y_test, n_queries,header,seed,filename,fields):\n",
    "    \n",
    "    results = []\n",
    "    for kernel in kernels:\n",
    "        for n_learner in n_learners:\n",
    "            for n_initial in n_initials:\n",
    "                \n",
    "                # make a copy of the data for use in this test\n",
    "                X_pool_gs = copy.deepcopy(X_pool)\n",
    "                y_pool_gs = copy.deepcopy(y_pool)\n",
    "\n",
    "                # get initial training set for each learner\n",
    "                initial_idx = []\n",
    "                for i in range(n_learner):\n",
    "                    initial_idx.append(np.random.choice(len(X_pool_gs), size=n_initial, replace=False))\n",
    "                \n",
    "                # initialize learners for Committee\n",
    "                learner_list = [ActiveLearner(estimator=GaussianProcessRegressor(kernel,random_state=seed),X_training=X_pool_gs[idx],y_training=y_pool_gs[idx]) for idx in initial_idx]\n",
    "                    \n",
    "                # create Committee\n",
    "                committee = CommitteeRegressor(\n",
    "                                learner_list=learner_list,\n",
    "                                query_strategy=max_std_sampling\n",
    "                            )\n",
    "\n",
    "                # active learning\n",
    "                run_active_learner_regression(committee, X_pool_gs, y_pool_gs, X_test, y_test, n_queries)\n",
    "\n",
    "                # score model\n",
    "                y_pred = committee.predict(X_test, return_std=False)\n",
    "                r2=r2_score(y_test,y_pred)\n",
    "                result = header + [kernel,kernel.length_scale, kernel.length_scale_bounds, n_learner, n_initial,n_queries, r2]\n",
    "                results.append(result)\n",
    "                \n",
    "                # append to file\n",
    "                write_results_to_file(filename, fields, result)\n",
    "                \n",
    "                # output to console\n",
    "                print('{}|{}|{}|{}|{}'.format(kernel, n_learner, n_initial,n_queries, r2))\n",
    "                \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search 1\n",
    "- Category: Committee\n",
    "- Learner: Gaussian Process\n",
    "- query_strategy: max_std_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matern(length_scale=0.644, nu=2.5)|10|80|200|0.5598867066215277\n",
      "Matern(length_scale=0.644, nu=1.5)|10|80|200|0.5481142207501702\n",
      "2\n",
      "CPU times: user 1h 23min 50s, sys: 1min 4s, total: 1h 24min 55s\n",
      "Wall time: 23min 12s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # 26 minutes with 2*2*10 Matern configurations at 100 queries - 2,5 learners\n",
    "# # 3 hours 4 minutes with 2*2*10 Matern configurations at 100 queries - 10,20 learners\n",
    "\n",
    "# header = ['Committee','Gaussian Process','max_std_sampling']\n",
    "\n",
    "\n",
    "# kernels = [Matern(length_scale=0.644444444, nu=5/2),\n",
    "#           Matern(length_scale=0.644444444, nu=3/2)]# for i in np.linspace(0.5,2,8)]\n",
    "# # kernels = [RBF(length_scale=i) for i in np.linspace(0.1,5,10)][1:]\n",
    "\n",
    "# n_learners = [10]\n",
    "\n",
    "# n_initials = [80]\n",
    "\n",
    "# n_queries = 200\n",
    "\n",
    "# results = gaussian_process_regressor_gs(kernels, \n",
    "#                                         n_learners, \n",
    "#                                         n_initials,\n",
    "#                                        X_train,\n",
    "#                                        y_train,\n",
    "#                                        X_test,\n",
    "#                                        y_test,\n",
    "#                                        n_queries,\n",
    "#                                        header,\n",
    "#                                        seed)\n",
    "# print(len(results))\n",
    "\n",
    "# # save results to file\n",
    "# fields = ['category','learner','query_strategy','kernel','length_scale', 'nu', 'n_learners', 'n_initial','n_queries','r2']\n",
    "# filename = 'data/gridsearch.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# write_results_to_file(filename,fields, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF(length_scale=0.812)|10|80|100|0.5298678617635948\n",
      "RBF(length_scale=0.812)|40|80|100|0.5408040482707657\n",
      "RBF(length_scale=0.812)|80|80|100|0.533652538931137\n",
      "RBF(length_scale=0.505)|10|80|100|0.5289926557712241\n",
      "RBF(length_scale=0.505)|40|80|100|0.5347708975586933\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 26 minutes with 2*2*10 Matern configurations at 100 queries - 2,5 learners\n",
    "# 3 hours 4 minutes with 2*2*10 Matern configurations at 100 queries - 10,20 learners\n",
    "# RBF takes 20 min each with 200 queries and 20 learners\n",
    "filename = 'data/gridsearch.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "header = ['Committee','Gaussian Process','max_std_sampling']\n",
    "fields = ['category','learner','query_strategy','kernel','length_scale', 'length_scale_bounds',\n",
    "          'noise_level', 'noise_level_bounds', 'n_learners', 'n_initial','n_queries','r2']\n",
    "\n",
    "# kernels = [Matern(length_scale=i) for i in np.linspace(0.1,5,10)]\n",
    "\n",
    "\n",
    "# kernels = [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.linspace(0.,0.418,5)]\n",
    "\n",
    "\n",
    "kernels = [RBF(length_scale=0.45,length_scale_bounds=(1e-2, 1e3)) + WhiteKernel(noise_level=i, noise_level_bounds=(1e-10, 1e+1)) for i in np.random.uniform(low=0.1,high=1.0,size=2)]\n",
    "\n",
    "\n",
    "# kernels = [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.random.uniform(low=0.38,high=1.0,size=20)] \\\n",
    "#         + [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.random.uniform(low=1,high=10,size=20)]\n",
    "\n",
    "\n",
    "# kernels = [RBF(length_scale=0.45, length_scale_bounds=(1e-2, 1e3))]\n",
    "\n",
    "\n",
    "# kernels = [RationalQuadratic(length_scale=i, alpha=j, length_scale_bounds=(1e-2, 1e3)) \n",
    "#            for i in np.linspace(0.5,10,5) \n",
    "#            for j in np.linspace(0.5,2,4)]\n",
    "\n",
    "n_learners = [10]\n",
    "\n",
    "n_initials = [80]\n",
    "\n",
    "n_queries = 1\n",
    "\n",
    "results = gaussian_process_regressor_gs(kernels, \n",
    "                                        n_learners, \n",
    "                                        n_initials,\n",
    "                                       X_train,\n",
    "                                       y_train,\n",
    "                                       X_test,\n",
    "                                       y_test,\n",
    "                                       n_queries,\n",
    "                                       header,\n",
    "                                       seed,\n",
    "                                       filename,\n",
    "                                       fields)\n",
    "print(len(results))\n",
    "\n",
    "# save results to file\n",
    "# fields = ['category','learner','query_strategy','kernel','length_scale', 'length_scale_bounds', 'n_learners', 'n_initial','n_queries','r2']\n",
    "# fields = ['category','learner','query_strategy','kernel','length_scale', 'n_learners', 'n_initial','n_queries','r2']\n",
    "\n",
    "# write_results_to_file(filename,fields, results)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search 1 - Results\n",
    "First three entries are initial tests.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Kernel|n_learners|n_initial|n_queries|$R^2$\n",
    "---|---|---|---|---\n",
    "Matern(length_scale=1.0, nu=1.5)|2|10|200|0.390\n",
    "Matern(length_scale=1.0, nu=1.5)|2|10|200|0.385\n",
    "Matern(length_scale=1.0, nu=1.5)|2|10|200|0.414\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Run with Parameters set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# 6.5 min for 2 learners 200 queries\n",
    "#?? why rerunning messes up r2 values\n",
    "\n",
    "# # make a copy of the data for use in this section\n",
    "# X_pool_comm = copy.deepcopy(X_train)\n",
    "# y_pool_comm = copy.deepcopy(y_train)\n",
    "\n",
    "# # kernel\n",
    "# # kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) \\\n",
    "# #          + WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e+1))\n",
    "# kernel = Matern(length_scale=1.0)\n",
    "\n",
    "# # generate initialization data sets\n",
    "# initial_idx = []\n",
    "# n_initial = 10\n",
    "# n_learners = 2\n",
    "# for each in range(n_learners):\n",
    "#     initial_idx.append(np.random.choice(len(X_pool_comm), size=n_initial, replace=False))\n",
    "\n",
    "\n",
    "# # initialize the regressors in the Committee\n",
    "# learner_list = [ActiveLearner(\n",
    "#                         estimator=GaussianProcessRegressor(kernel),\n",
    "#                         X_training=X_pool_comm[idx],\n",
    "#                         y_training=y_pool_comm[idx]\n",
    "#                 )\n",
    "#                 for idx in initial_idx]\n",
    "\n",
    "# # initializing the Committee\n",
    "# committee = CommitteeRegressor(\n",
    "#     learner_list=learner_list,\n",
    "#     query_strategy=max_std_sampling\n",
    "# )\n",
    "\n",
    "# # active regression\n",
    "# n_queries = 200\n",
    "# history_comm = run_active_learner_regression(committee, X_pool_comm, y_pool_comm, X_test, y_test, n_queries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4. Score model (5 points)\n",
    "**The quality of the model should be measured on the test set as $R^2$ score. The minimum acceptable $R^2$ score is 0.6.**\n",
    "\n",
    "**TODO**\n",
    "- **Score the model on the test set using $R^2$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score the final model\n",
    "y_pred_comm = committee.predict(X_test, return_std=False)\n",
    "r2=r2_score(y_test,y_pred_comm)\n",
    "print(\"R2 for test set\",r2)\n",
    "\n",
    "# compare against R2 of the remaining pool\n",
    "y_pred_comm_pool = committee.predict(X_pool_comm)\n",
    "r2_pool = r2_score(y_pool_comm, y_pred_comm_pool)\n",
    "print(\"R2 for pool\",r2_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5. Compare with Random Active Learner (5 points)\n",
    "**TODO**\n",
    "- **Compare your results with no active learning scheme by training a random forest classifier on the same amount of data points, but selected randomly. (An Active Learner with a random query strategy.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_query(learner, X):\n",
    "   \n",
    "    n_samples = len(X)\n",
    "    query_idx = np.random.choice(range(n_samples))\n",
    "    return query_idx, X[query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# copy data for this section\n",
    "X_pool_rand = copy.deepcopy(X_train)\n",
    "y_pool_rand = copy.deepcopy(y_train)\n",
    "\n",
    "# use the same initialization to make comparison meaningful\n",
    "initial_rand = initial_idx[0]\n",
    "\n",
    "regressor = ActiveLearner(\n",
    "    estimator=RandomForestRegressor(n_estimators = 20, max_depth = 6, random_state = seed),\n",
    "    query_strategy=random_query,\n",
    "    X_training=X_pool_rand[initial_rand], \n",
    "    y_training=y_pool_rand[initial_rand]\n",
    ")\n",
    "\n",
    "\n",
    "history_rand = []\n",
    "for q in range(n_queries):\n",
    "    \n",
    "    # get sample\n",
    "    X_sample, y_sample, query_idx = get_next_sample(regressor, X_pool_rand, y_pool_rand)\n",
    "    \n",
    "    # use new sample to update the model\n",
    "    regressor.teach(X_sample, y_sample)\n",
    "\n",
    "    # remove labeled instance from pool\n",
    "    X_pool_rand = np.delete(X_pool_rand, query_idx, axis=0)\n",
    "    y_pool_rand = np.delete(y_pool_rand, query_idx)\n",
    "    \n",
    "    # score the current model\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    history_rand.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the two results\n",
    "fig, ax = plt.subplots(figsize=(8.5, 6), dpi=130)\n",
    "\n",
    "ax.plot(history_comm)\n",
    "ax.scatter(range(len(history_comm)), history_comm, s=13, label = 'Committee')\n",
    "\n",
    "ax.plot(history_rand)\n",
    "ax.scatter(range(len(history_rand)), history_rand, s=13, label = 'RF')\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "# ax.set_title('Incremental classification accuracy')\n",
    "# ax.set_xlabel('Query iteration')\n",
    "# ax.set_ylabel('Classification Accuracy')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?? why compare test and pool \n",
    "#?? use version with missing entries\n",
    "# score the final model\n",
    "y_pred_rand = regressor.predict(X_test)\n",
    "r2=r2_score(y_test,y_pred_rand)\n",
    "print(\"R2 for test set\",r2)\n",
    "\n",
    "# compare against R2 of the remaining pool\n",
    "y_pred_rand_pool = committee.predict(X_pool_rand)\n",
    "r2_pool = r2_score(y_pool_rand, y_pred_rand_pool)\n",
    "print(\"R2 for pool\",r2_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6. Summary (5 points)\n",
    "**TODO**\n",
    "- **Write a paragraph about your method, describe your observations and difficulties.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method\n",
    "- Consider encoding sequence k-mers together because order of sequence is important too. This controls protein shape, which should strongly affect binding. Worried about N < J.\n",
    "- Tried various regressors: Ridge, Random Forest, Gaussian Process. GP did the best on the entire training set, with Ridge being a close second.\n",
    "- Grid search varying kernel, number of learners in Committee, and initial training size\n",
    "- Run grid parameters through linear regression to determine regression coefficients and figure out importance of each parameter\n",
    "\n",
    "\n",
    "### Difficulties\n",
    "- understanding kernel in Gaussian process (which to use)\n",
    "- understanding what to modify to improve R2 values. Is it the encoding? Is it the number of committee members? Is it the query strategy? Is it the hyperparmeters or kernel for the regressor?\n",
    "- Rerunning cells messes up R2 value. Goes from 0.3 to -0.01.\n",
    "- understanding range of hyperparameters like length_scale for kernels\n",
    "- testing takes time (3-6 min per iteration, can run for 6 hours testing 120 configurations)\n",
    "\n",
    "\n",
    "### Observations\n",
    "#### Grid Search 1\n",
    "- `n_learners`: More committee members is better (20 outperforms 2,5,10 when all other hyperparameters are held constant). Positive correlation.\n",
    "- `n_initial`: Larger initial training set is better (80 outperforms 10,20,40). Positive correlation.\n",
    "- `scale_length`: seems to have slightly negative correlation (larger values result in smaller r2). Overall, barely an effect with Matern kernel.\n",
    "\n",
    "\n",
    "#### Final\n",
    "- AL is better than random eventually\n",
    "- after about 100 queries, AL remains better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
