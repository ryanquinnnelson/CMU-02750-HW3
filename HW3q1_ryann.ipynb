{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF, WhiteKernel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from modAL.models import BayesianOptimizer, ActiveLearner, CommitteeRegressor\n",
    "from modAL.acquisition import max_EI\n",
    "from modAL.disagreement import max_std_sampling\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "# import seqlogo\n",
    "\n",
    "import copy\n",
    "\n",
    "### Set random seed\n",
    "seed = 5\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "### Suppresses Warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Data Load (5 points)\n",
    "**In this question, you need to build a regression model with active learning for predicting binding affinity between MHC class I and small peptides. The dataset is provided in file `hw3_data.csv`.**\n",
    "\n",
    "**TODO**\n",
    "- **Read the data into the jupyter notebook. Columns 2 and 3 in the dataset file correspond to peptide sequences and pIC50 values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9051, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allele</th>\n",
       "      <th>seq</th>\n",
       "      <th>pIC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seq0</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>AIIDYIAYM</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seq1</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>AIYDTMQYV</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seq2</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>ALATFTVNI</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seq3</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>ALDEGLLPV</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seq4</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>ALFPIIWAL</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       allele        seq  pIC50\n",
       "0  seq0  HLA-A*02:01  AIIDYIAYM    9.0\n",
       "1  seq1  HLA-A*02:01  AIYDTMQYV    9.0\n",
       "2  seq2  HLA-A*02:01  ALATFTVNI    9.0\n",
       "3  seq3  HLA-A*02:01  ALDEGLLPV    9.0\n",
       "4  seq4  HLA-A*02:01  ALFPIIWAL    9.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/hw3_data.csv', delimiter=',',header=0)\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Encode Data (10 points)\n",
    "**Since we are dealing with machine learning models, you need to convert peptide sequences into feature vectors. The simplest way to do this is to use a one-hot encoding.**\n",
    "\n",
    "**Each character in the amino acid alphabet will correspond to a binary vector with a single 1 and all zeros. The size of the vector is equal to the size of the amino acid alphabet. The position of 1 encodes a specific amino acid. The resulting feature vector for a peptide is a concatenation of the feature vectors of its amino acids. Since we are dealing with 9-mers here, the size of the feature vector for a peptide should be equal to 9*(size of the amino acid alphabet).**\n",
    "\n",
    "**TODO**\n",
    "- **Encode the data.**\n",
    "- **Split data into train and test datasets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Data\n",
    "I want to keep some notion of the order of the amino acids. The 3D structure they form is vital for predicting binding quality. One possible way is to group letters in order. How do I decide how many letters constitutes a group?\n",
    "\n",
    "Ex: 3-mers\n",
    "```\n",
    "AIIDYIAYM\n",
    "AII\n",
    " IID\n",
    "  IDY\n",
    "    ...\n",
    "      AYM\n",
    "```\n",
    "\n",
    "3-mers results in N < J, where N is the number of samples and J is the number of features. If we want to use multivariate regression, we'll need to use ridge regression or some other sparse form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['seq'].str.len().unique()  # every seq is length 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate columns for each amino acid\n",
    "for i in range(9):\n",
    "    colname='seq'+str(i)\n",
    "    data[colname] = [x[i] for x in data['seq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allele</th>\n",
       "      <th>seq</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>seq0</th>\n",
       "      <th>seq1</th>\n",
       "      <th>seq2</th>\n",
       "      <th>seq3</th>\n",
       "      <th>seq4</th>\n",
       "      <th>seq5</th>\n",
       "      <th>seq6</th>\n",
       "      <th>seq7</th>\n",
       "      <th>seq8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seq0</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>AIIDYIAYM</td>\n",
       "      <td>9.0</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>D</td>\n",
       "      <td>Y</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       allele        seq  pIC50 seq0 seq1 seq2 seq3 seq4 seq5 seq6  \\\n",
       "0  seq0  HLA-A*02:01  AIIDYIAYM    9.0    A    I    I    D    Y    I    A   \n",
       "\n",
       "  seq7 seq8  \n",
       "0    Y    M  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique letters\n",
    "len(data['seq0'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create triplets\n",
    "# k = 3\n",
    "# count = 9-k+1\n",
    "# start=0\n",
    "# end=k\n",
    "# for i in range(count):\n",
    "#     colname='triplet'+str(i)\n",
    "#     data[colname] = [x[start:end] for x in data['seq']]\n",
    "#     start +=1\n",
    "#     end +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allele</th>\n",
       "      <th>seq</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>seq0</th>\n",
       "      <th>seq1</th>\n",
       "      <th>seq2</th>\n",
       "      <th>seq3</th>\n",
       "      <th>seq4</th>\n",
       "      <th>seq5</th>\n",
       "      <th>seq6</th>\n",
       "      <th>seq7</th>\n",
       "      <th>seq8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seq0</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>AIIDYIAYM</td>\n",
       "      <td>9.0</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>D</td>\n",
       "      <td>Y</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       allele        seq  pIC50 seq0 seq1 seq2 seq3 seq4 seq5 seq6  \\\n",
       "0  seq0  HLA-A*02:01  AIIDYIAYM    9.0    A    I    I    D    Y    I    A   \n",
       "\n",
       "  seq7 seq8  \n",
       "0    Y    M  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9051, 9)\n",
      "(9051,)\n"
     ]
    }
   ],
   "source": [
    "X_df = data.drop(['pIC50','id','allele', 'seq'],axis=1)\n",
    "y = data['pIC50']\n",
    "print(X_df.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq0</th>\n",
       "      <th>seq1</th>\n",
       "      <th>seq2</th>\n",
       "      <th>seq3</th>\n",
       "      <th>seq4</th>\n",
       "      <th>seq5</th>\n",
       "      <th>seq6</th>\n",
       "      <th>seq7</th>\n",
       "      <th>seq8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>D</td>\n",
       "      <td>Y</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seq0 seq1 seq2 seq3 seq4 seq5 seq6 seq7 seq8\n",
       "0    A    I    I    D    Y    I    A    Y    M"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(9051, 180)\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X_enc = enc.fit_transform(X_df)\n",
    "print(type(X_enc))\n",
    "print(X_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(9051, 180)\n",
      "(9051,)\n"
     ]
    }
   ],
   "source": [
    "# convert to numpy array\n",
    "X_pool=sparse.csr_matrix.toarray(X_enc)\n",
    "print(type(X_pool))\n",
    "print(X_pool.shape)\n",
    "y_pool = y.to_numpy()\n",
    "print(y_pool.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "- ~~X_initial: set of samples removed from data pool for initialization~~\n",
    "- X_train: 2/3 of data pool\n",
    "- X_test: 1/3 of data pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(6064, 180)\n",
      "(6064,)\n",
      "(2987, 180)\n",
      "(2987,)\n"
     ]
    }
   ],
   "source": [
    "#?? initial training set for active learners?\n",
    "# n_initial = 10\n",
    "\n",
    "# # select random instances to use as initial active learning training set\n",
    "# idx_initial = np.random.choice(X_np.shape[0], n_initial)\n",
    "# X_initial = X_np[idx_initial]\n",
    "# y_initial = y_np[idx_initial]\n",
    "# print(X_initial.shape)\n",
    "# print(y_initial.shape)\n",
    "\n",
    "\n",
    "# # remove from pool of data for testing and training\n",
    "# X_pool = np.delete(X_np, idx_initial, axis=0)\n",
    "# y_pool = np.delete(y_np, idx_initial, axis=0)\n",
    "# print(X_pool.shape)\n",
    "# print(y_pool.shape)\n",
    "\n",
    "\n",
    "# split remaining pool of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pool, y_pool, test_size=0.33)\n",
    "print()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with offline learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4769976135583013\n",
      "CPU times: user 355 ms, sys: 6.26 ms, total: 361 ms\n",
      "Wall time: 363 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train RFC model on entire pool of data\n",
    "rf = RandomForestRegressor(n_estimators = 20, \n",
    "                            max_depth = 6, \n",
    "                            random_state = seed)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "print(rf.score(X_test,y_test))  # uses R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6323258584401178\n",
      "CPU times: user 35.3 ms, sys: 5.96 ms, total: 41.3 ms\n",
      "Wall time: 17.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = Ridge(alpha=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_test,y_test))  # uses R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 12 minutes for (5931,180)\n",
    "\n",
    "# kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) \\\n",
    "#          + WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e+1))\n",
    "\n",
    "# gpr = GaussianProcessRegressor(kernel,random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test)) #0.69 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Build Active Learning  model (20 points)\n",
    "**Now you can start building the model with active learning! We do not give you any specific instructions as to which algorithm to implement. You can use something similar to [this](https://modal-python.readthedocs.io/en/latest/content/examples/active_regression.html) example in modAL documentation, or query-by-committee when a label is requested for samples which the committee is least confident about or anything else covered in the lectures.**\n",
    "\n",
    "**TODO**\n",
    "- **Implement an active learning algorithm using modAL.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_sample(learner, X, y):\n",
    "    \n",
    "    # call the query strategy defined in the learner to obtain a new sample\n",
    "    query_idx, query_sample = learner.query(X)\n",
    "    \n",
    "    # modify indexing to interpret as collection of one element with d features\n",
    "    query_sample_reshaped = query_sample.reshape(1,-1)\n",
    "   \n",
    "    # obtain the query label\n",
    "    query_label = y[query_idx]\n",
    "\n",
    "    # modify indexing to interpret as 1D array of one element\n",
    "    query_label_reshaped = query_label.reshape(1,)\n",
    "    \n",
    "    return query_sample_reshaped, query_label_reshaped, query_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_active_learner_regression(learner, X_pool, y_pool, X_test, y_test, n_queries):\n",
    "\n",
    "#     history = [] # score history\n",
    "    \n",
    "#     # score model before active learning starts\n",
    "#     y_pred = learner.predict(X_test, return_std=False)\n",
    "#     history.append(r2_score(y_test,y_pred))  # y_true,y_pred\n",
    "\n",
    "    # perform active learning\n",
    "    for q in range(n_queries):\n",
    "\n",
    "        # get sample\n",
    "        X_sample, y_sample, query_idx = get_next_sample(learner, X_pool, y_pool)\n",
    "\n",
    "        # use new sample to update the model\n",
    "        learner.teach(X_sample, y_sample)\n",
    "\n",
    "#         # score current model\n",
    "#         y_pred = learner.predict(X_test, return_std=False)\n",
    "#         history.append(r2_score(y_test,y_pred))\n",
    "        \n",
    "        # remove labeled instance from pool\n",
    "        X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, query_idx)\n",
    "        \n",
    "#     return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_process_regressor_gs(kernels, n_learners, n_initials, X_pool, y_pool, X_test, y_test, n_queries):\n",
    "    \n",
    "    results = []\n",
    "    for kernel in kernels:\n",
    "        for n_learner in n_learners:\n",
    "            for n_initial in n_initials:\n",
    "                \n",
    "                # make a copy of the data for use in this test\n",
    "                X_pool_gs = copy.deepcopy(X_pool)\n",
    "                y_pool_gs = copy.deepcopy(y_pool)\n",
    "\n",
    "                # get initial training set for each learner\n",
    "                initial_idx = []\n",
    "                for i in range(n_learner):\n",
    "                    initial_idx.append(np.random.choice(len(X_pool_gs), size=n_initial, replace=False))\n",
    "                \n",
    "                # initialize learners for Committee\n",
    "                learner_list = [ActiveLearner(estimator=GaussianProcessRegressor(kernel),X_training=X_pool_gs[idx],y_training=y_pool_gs[idx]) for idx in initial_idx]\n",
    "                    \n",
    "                # create Committee\n",
    "                committee = CommitteeRegressor(\n",
    "                                learner_list=learner_list,\n",
    "                                query_strategy=max_std_sampling\n",
    "                            )\n",
    "\n",
    "                # active learning\n",
    "                run_active_learner_regression(committee, X_pool_gs, y_pool_gs, X_test, y_test, n_queries)\n",
    "\n",
    "                # score model\n",
    "                y_pred = committee.predict(X_test, return_std=False)\n",
    "                r2=r2_score(y_test,y_pred)\n",
    "                result=(kernel, n_learner, n_initial,n_queries, r2)\n",
    "                results.append(result)\n",
    "                print(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search 1\n",
    "- Category: Committee\n",
    "- Learner: Gaussian Process\n",
    "- query_strategy: max_std_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Matern(length_scale=0.1, nu=1.5), 2, 10, -14.42578134531581)\n",
      "(Matern(length_scale=0.1, nu=1.5), 2, 20, -14.425781344738391)\n",
      "(Matern(length_scale=0.1, nu=1.5), 5, 10, -14.425781345536818)\n",
      "(Matern(length_scale=0.1, nu=1.5), 5, 20, -14.425781345621811)\n",
      "(Matern(length_scale=0.644, nu=1.5), 2, 10, 0.32517248344790817)\n",
      "(Matern(length_scale=0.644, nu=1.5), 2, 20, 0.32775446605756775)\n",
      "(Matern(length_scale=0.644, nu=1.5), 5, 10, 0.3374298007644476)\n",
      "(Matern(length_scale=0.644, nu=1.5), 5, 20, 0.3722722826277567)\n",
      "(Matern(length_scale=1.19, nu=1.5), 2, 10, 0.35401491300925436)\n",
      "(Matern(length_scale=1.19, nu=1.5), 2, 20, 0.3098819680547852)\n",
      "(Matern(length_scale=1.19, nu=1.5), 5, 10, 0.37378798784156786)\n",
      "(Matern(length_scale=1.19, nu=1.5), 5, 20, 0.31331444757024396)\n",
      "(Matern(length_scale=1.73, nu=1.5), 2, 10, 0.28963955154381804)\n",
      "(Matern(length_scale=1.73, nu=1.5), 2, 20, 0.3600227240463074)\n",
      "(Matern(length_scale=1.73, nu=1.5), 5, 10, 0.32415327902059754)\n",
      "(Matern(length_scale=1.73, nu=1.5), 5, 20, 0.33838739467921297)\n",
      "(Matern(length_scale=2.28, nu=1.5), 2, 10, 0.2949631729972585)\n",
      "(Matern(length_scale=2.28, nu=1.5), 2, 20, 0.35703597185402824)\n",
      "(Matern(length_scale=2.28, nu=1.5), 5, 10, 0.3419522164640735)\n",
      "(Matern(length_scale=2.28, nu=1.5), 5, 20, 0.3324226775467056)\n",
      "(Matern(length_scale=2.82, nu=1.5), 2, 10, 0.3274022975194397)\n",
      "(Matern(length_scale=2.82, nu=1.5), 2, 20, 0.31700366099855026)\n",
      "(Matern(length_scale=2.82, nu=1.5), 5, 10, 0.3403386699110982)\n",
      "(Matern(length_scale=2.82, nu=1.5), 5, 20, 0.3781787734856924)\n",
      "(Matern(length_scale=3.37, nu=1.5), 2, 10, 0.29104906545740383)\n",
      "(Matern(length_scale=3.37, nu=1.5), 2, 20, 0.33555035593667515)\n",
      "(Matern(length_scale=3.37, nu=1.5), 5, 10, 0.3238306242826957)\n",
      "(Matern(length_scale=3.37, nu=1.5), 5, 20, 0.392697923969199)\n",
      "(Matern(length_scale=3.91, nu=1.5), 2, 10, 0.3172058588991009)\n",
      "(Matern(length_scale=3.91, nu=1.5), 2, 20, 0.30410393445326)\n",
      "(Matern(length_scale=3.91, nu=1.5), 5, 10, 0.30061536714493775)\n",
      "(Matern(length_scale=3.91, nu=1.5), 5, 20, 0.3338338374229338)\n",
      "(Matern(length_scale=4.46, nu=1.5), 2, 10, 0.26628787300604895)\n",
      "(Matern(length_scale=4.46, nu=1.5), 2, 20, 0.3607860318450353)\n",
      "(Matern(length_scale=4.46, nu=1.5), 5, 10, 0.29403231874615665)\n",
      "(Matern(length_scale=4.46, nu=1.5), 5, 20, 0.420076313138967)\n",
      "(Matern(length_scale=5, nu=1.5), 2, 10, 0.3313777494505634)\n",
      "(Matern(length_scale=5, nu=1.5), 2, 20, 0.35911641912632875)\n",
      "(Matern(length_scale=5, nu=1.5), 5, 10, 0.3496789760110526)\n",
      "(Matern(length_scale=5, nu=1.5), 5, 20, 0.36846897923498034)\n",
      "CPU times: user 1h 43min 4s, sys: 1min 17s, total: 1h 44min 21s\n",
      "Wall time: 26min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 26 minutes with 2*2*10 Matern configurations at 100 queries\n",
    "\n",
    "kernels = [Matern(length_scale=i) for i in np.linspace(0.1,5,10)]\n",
    "\n",
    "n_learners = [10,20]\n",
    "\n",
    "n_initials = [40,80]\n",
    "\n",
    "n_queries = 100\n",
    "\n",
    "results = gaussian_process_regressor_gs(kernels, \n",
    "                                        n_learners, \n",
    "                                        n_initials,\n",
    "                                       X_train,\n",
    "                                       y_train,\n",
    "                                       X_test,\n",
    "                                       y_test,\n",
    "                                       n_queries)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search 1 - Results\n",
    "First three entries are initial tests.\n",
    "\n",
    "```\n",
    "(Matern(length_scale=0.1, nu=1.5), 2, 10, -14.42578134531581)\n",
    "(Matern(length_scale=0.1, nu=1.5), 2, 20, -14.425781344738391)\n",
    "(Matern(length_scale=0.1, nu=1.5), 5, 10, -14.425781345536818)\n",
    "(Matern(length_scale=0.1, nu=1.5), 5, 20, -14.425781345621811)\n",
    "(Matern(length_scale=0.644, nu=1.5), 2, 10, 0.32517248344790817)\n",
    "(Matern(length_scale=0.644, nu=1.5), 2, 20, 0.32775446605756775)\n",
    "(Matern(length_scale=0.644, nu=1.5), 5, 10, 0.3374298007644476)\n",
    "(Matern(length_scale=0.644, nu=1.5), 5, 20, 0.3722722826277567)\n",
    "(Matern(length_scale=1.19, nu=1.5), 2, 10, 0.35401491300925436)\n",
    "(Matern(length_scale=1.19, nu=1.5), 2, 20, 0.3098819680547852)\n",
    "(Matern(length_scale=1.19, nu=1.5), 5, 10, 0.37378798784156786)\n",
    "(Matern(length_scale=1.19, nu=1.5), 5, 20, 0.31331444757024396)\n",
    "(Matern(length_scale=1.73, nu=1.5), 2, 10, 0.28963955154381804)\n",
    "(Matern(length_scale=1.73, nu=1.5), 2, 20, 0.3600227240463074)\n",
    "(Matern(length_scale=1.73, nu=1.5), 5, 10, 0.32415327902059754)\n",
    "(Matern(length_scale=1.73, nu=1.5), 5, 20, 0.33838739467921297)\n",
    "(Matern(length_scale=2.28, nu=1.5), 2, 10, 0.2949631729972585)\n",
    "(Matern(length_scale=2.28, nu=1.5), 2, 20, 0.35703597185402824)\n",
    "(Matern(length_scale=2.28, nu=1.5), 5, 10, 0.3419522164640735)\n",
    "(Matern(length_scale=2.28, nu=1.5), 5, 20, 0.3324226775467056)\n",
    "(Matern(length_scale=2.82, nu=1.5), 2, 10, 0.3274022975194397)\n",
    "(Matern(length_scale=2.82, nu=1.5), 2, 20, 0.31700366099855026)\n",
    "(Matern(length_scale=2.82, nu=1.5), 5, 10, 0.3403386699110982)\n",
    "(Matern(length_scale=2.82, nu=1.5), 5, 20, 0.3781787734856924)\n",
    "(Matern(length_scale=3.37, nu=1.5), 2, 10, 0.29104906545740383)\n",
    "(Matern(length_scale=3.37, nu=1.5), 2, 20, 0.33555035593667515)\n",
    "(Matern(length_scale=3.37, nu=1.5), 5, 10, 0.3238306242826957)\n",
    "(Matern(length_scale=3.37, nu=1.5), 5, 20, 0.392697923969199)\n",
    "(Matern(length_scale=3.91, nu=1.5), 2, 10, 0.3172058588991009)\n",
    "(Matern(length_scale=3.91, nu=1.5), 2, 20, 0.30410393445326)\n",
    "(Matern(length_scale=3.91, nu=1.5), 5, 10, 0.30061536714493775)\n",
    "(Matern(length_scale=3.91, nu=1.5), 5, 20, 0.3338338374229338)\n",
    "(Matern(length_scale=4.46, nu=1.5), 2, 10, 0.26628787300604895)\n",
    "(Matern(length_scale=4.46, nu=1.5), 2, 20, 0.3607860318450353)\n",
    "(Matern(length_scale=4.46, nu=1.5), 5, 10, 0.29403231874615665)\n",
    "(Matern(length_scale=4.46, nu=1.5), 5, 20, 0.420076313138967)\n",
    "(Matern(length_scale=5, nu=1.5), 2, 10, 0.3313777494505634)\n",
    "(Matern(length_scale=5, nu=1.5), 2, 20, 0.35911641912632875)\n",
    "(Matern(length_scale=5, nu=1.5), 5, 10, 0.3496789760110526)\n",
    "(Matern(length_scale=5, nu=1.5), 5, 20, 0.36846897923498034)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Kernel|n_learners|n_initial|n_queries|$R^2$\n",
    "---|---|---|---|---\n",
    "Matern(length_scale=1.0, nu=1.5)|2|10|200|0.390\n",
    "Matern(length_scale=1.0, nu=1.5)|2|10|200|0.385\n",
    "Matern(length_scale=1.0, nu=1.5)|2|10|200|0.414\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Run with Parameters set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# 6.5 min for 2 learners 200 queries\n",
    "#?? why rerunning messes up r2 values\n",
    "\n",
    "# # make a copy of the data for use in this section\n",
    "# X_pool_comm = copy.deepcopy(X_train)\n",
    "# y_pool_comm = copy.deepcopy(y_train)\n",
    "\n",
    "# # kernel\n",
    "# # kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) \\\n",
    "# #          + WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e+1))\n",
    "# kernel = Matern(length_scale=1.0)\n",
    "\n",
    "# # generate initialization data sets\n",
    "# initial_idx = []\n",
    "# n_initial = 10\n",
    "# n_learners = 2\n",
    "# for each in range(n_learners):\n",
    "#     initial_idx.append(np.random.choice(len(X_pool_comm), size=n_initial, replace=False))\n",
    "\n",
    "\n",
    "# # initialize the regressors in the Committee\n",
    "# learner_list = [ActiveLearner(\n",
    "#                         estimator=GaussianProcessRegressor(kernel),\n",
    "#                         X_training=X_pool_comm[idx],\n",
    "#                         y_training=y_pool_comm[idx]\n",
    "#                 )\n",
    "#                 for idx in initial_idx]\n",
    "\n",
    "# # initializing the Committee\n",
    "# committee = CommitteeRegressor(\n",
    "#     learner_list=learner_list,\n",
    "#     query_strategy=max_std_sampling\n",
    "# )\n",
    "\n",
    "# # active regression\n",
    "# n_queries = 200\n",
    "# history_comm = run_active_learner_regression(committee, X_pool_comm, y_pool_comm, X_test, y_test, n_queries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4. Score model (5 points)\n",
    "**The quality of the model should be measured on the test set as $R^2$ score. The minimum acceptable $R^2$ score is 0.6.**\n",
    "\n",
    "**TODO**\n",
    "- **Score the model on the test set using $R^2$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score the final model\n",
    "y_pred_comm = committee.predict(X_test, return_std=False)\n",
    "r2=r2_score(y_test,y_pred_comm)\n",
    "print(\"R2 for test set\",r2)\n",
    "\n",
    "# compare against R2 of the remaining pool\n",
    "y_pred_comm_pool = committee.predict(X_pool_comm)\n",
    "r2_pool = r2_score(y_pool_comm, y_pred_comm_pool)\n",
    "print(\"R2 for pool\",r2_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5. Compare with Random Active Learner (5 points)\n",
    "**TODO**\n",
    "- **Compare your results with no active learning scheme by training a random forest classifier on the same amount of data points, but selected randomly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_query(learner, X):\n",
    "   \n",
    "    n_samples = len(X)\n",
    "    query_idx = np.random.choice(range(n_samples))\n",
    "    return query_idx, X[query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# copy data for this section\n",
    "X_pool_rand = copy.deepcopy(X_train)\n",
    "y_pool_rand = copy.deepcopy(y_train)\n",
    "\n",
    "# use the same initialization to make comparison meaningful\n",
    "initial_rand = initial_idx[0]\n",
    "\n",
    "regressor = ActiveLearner(\n",
    "    estimator=RandomForestRegressor(n_estimators = 20, max_depth = 6, random_state = seed),\n",
    "    query_strategy=random_query,\n",
    "    X_training=X_pool_rand[initial_rand], \n",
    "    y_training=y_pool_rand[initial_rand]\n",
    ")\n",
    "\n",
    "\n",
    "history_rand = []\n",
    "for q in range(n_queries):\n",
    "    \n",
    "    # get sample\n",
    "    X_sample, y_sample, query_idx = get_next_sample(regressor, X_pool_rand, y_pool_rand)\n",
    "    \n",
    "    # use new sample to update the model\n",
    "    regressor.teach(X_sample, y_sample)\n",
    "\n",
    "    # remove labeled instance from pool\n",
    "    X_pool_rand = np.delete(X_pool_rand, query_idx, axis=0)\n",
    "    y_pool_rand = np.delete(y_pool_rand, query_idx)\n",
    "    \n",
    "    # score the current model\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    history_rand.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the two results\n",
    "fig, ax = plt.subplots(figsize=(8.5, 6), dpi=130)\n",
    "\n",
    "ax.plot(history_comm)\n",
    "ax.scatter(range(len(history_comm)), history_comm, s=13, label = 'Committee')\n",
    "\n",
    "ax.plot(history_rand)\n",
    "ax.scatter(range(len(history_rand)), history_rand, s=13, label = 'RF')\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "# ax.set_title('Incremental classification accuracy')\n",
    "# ax.set_xlabel('Query iteration')\n",
    "# ax.set_ylabel('Classification Accuracy')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?? why compare test and pool \n",
    "#?? use version with missing entries\n",
    "# score the final model\n",
    "y_pred_rand = regressor.predict(X_test)\n",
    "r2=r2_score(y_test,y_pred_rand)\n",
    "print(\"R2 for test set\",r2)\n",
    "\n",
    "# compare against R2 of the remaining pool\n",
    "y_pred_rand_pool = committee.predict(X_pool_rand)\n",
    "r2_pool = r2_score(y_pool_rand, y_pred_rand_pool)\n",
    "print(\"R2 for pool\",r2_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6. Summary (5 points)\n",
    "**TODO**\n",
    "- **Write a paragraph about your method, describe your observations and difficulties.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method\n",
    "- Consider encoding sequence k-mers together because order of sequence is important too. This controls protein shape, which should strongly affect binding. Worried about N < J.\n",
    "- Tried various regressors: Ridge, Random Forest, Gaussian Process. GP did the best on the entire training set, with Ridge being a close second.\n",
    "- Grid search varying kernel, number of learners in Committee, and initial training size\n",
    "\n",
    "\n",
    "### Difficulties\n",
    "- understanding kernel in Gaussian process (which to use)\n",
    "- understanding what to modify to improve R2 values. Is it the encoding? Is it the number of committee members? Is it the query strategy? Is it the hyperparmeters or kernel for the regressor?\n",
    "- Rerunning cells messes up R2 value. Goes from 0.3 to -0.01.\n",
    "- understanding range of hyperparameters like length_scale for kernels\n",
    "- testing takes time (3-6 min per iteration, can run for 6 hours testing 120 configurations)\n",
    "\n",
    "### Observations\n",
    "\n",
    "- Found that kernel length_scale makes a much larger impact than number of committee members or size of initial training set\n",
    "\n",
    "- AL is better than random eventually\n",
    "- after about 100 queries, AL remains better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
