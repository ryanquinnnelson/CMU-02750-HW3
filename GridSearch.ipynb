{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF, WhiteKernel,ExpSineSquared,DotProduct,RationalQuadratic\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# scipy\n",
    "from scipy import sparse\n",
    "\n",
    "# custom packages\n",
    "from packages.gridsearch import gridsearch as gs\n",
    "\n",
    "\n",
    "\n",
    "### Set random seed\n",
    "seed = 5\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "### Suppresses Warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9051, 4)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/hw3_data.csv', delimiter=',',header=0)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate columns for each amino acid\n",
    "for i in range(9): # all seq are length 9\n",
    "    colname='seq'+str(i)\n",
    "    data[colname] = [x[i] for x in data['seq']]\n",
    "\n",
    "# separate features and target, remove unnecessary columns\n",
    "X_df = data.drop(['pIC50','id','allele', 'seq'],axis=1)\n",
    "y = data['pIC50']\n",
    "\n",
    "# encode features\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X_enc = enc.fit_transform(X_df)\n",
    "\n",
    "# ?? standardize target\n",
    "\n",
    "# convert to numpy array ?? is this necessary\n",
    "X_pool=sparse.csr_matrix.toarray(X_enc)\n",
    "y_pool = y.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6064, 180)\n",
      "(6064,)\n",
      "(2987, 180)\n",
      "(2987,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pool, y_pool, test_size=0.33)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Experiments with offline learners and kernels\n",
    "To see if a particular regressor or kernel works better on the data than any other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Random Forest Regressor\n",
    "Doesn't meet 0.6 threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # train RFC model on entire pool of data\n",
    "# rf = RandomForestRegressor(n_estimators = 20, \n",
    "#                             max_depth = 6, \n",
    "#                             random_state = seed)\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# # calculate accuracy\n",
    "# print(rf.score(X_test,y_test)) #0.476"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Ridge Regression\n",
    "Barely passable to meet 0.6 threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# clf = Ridge(alpha=1.0)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print(clf.score(X_test,y_test))  #0.632"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Ridge Regression with variable alpha\n",
    "Did not dramatically improve score. (0.63 -> 0.65 maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search had no significant improvement \n",
    "# for i in np.linspace(0.1,5,50):\n",
    "#     clf = Ridge(alpha=i)\n",
    "#     clf.fit(X_train, y_train)\n",
    "\n",
    "#     print(np.round(i,2),np.round(clf.score(X_test,y_test),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 RBF Kernel\n",
    "Good score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #2 min\n",
    "\n",
    "# # checking if WhiteKernel is helping or not\n",
    "# kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3))\n",
    "\n",
    "# gpr = GaussianProcessRegressor(kernel,random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test)) #0.6885"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 RBF + WhiteKernel\n",
    "WhiteKernel doesn't seem to improve score. Good score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 15 minutes for (5931,180)\n",
    "\n",
    "# check if WhiteKernel helps or not\n",
    "# kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) \\\n",
    "#          + WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e+1))\n",
    "\n",
    "# gpr = GaussianProcessRegressor(kernel,random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test)) #0.686 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 RBF no length_scale_bounds\n",
    "Seems to increase runtime slightly. No effect on results. Good score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 2 min\n",
    "\n",
    "# # checking if bounds is helping or not\n",
    "# kernel = RBF(length_scale=1.0)\n",
    "\n",
    "# gpr = GaussianProcessRegressor(kernel,random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test))  #0.6885"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 RationalQuadratic kernel\n",
    "Good score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 3.5 min\n",
    "\n",
    "# kernel = RationalQuadratic(length_scale=1.0, alpha=1.5, length_scale_bounds=(1e-2, 1e3))\n",
    "# gpr = GaussianProcessRegressor(kernel,random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test)) #0.6888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 DotProduct + WhiteKernel\n",
    "Barely passable score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 2 min\n",
    "\n",
    "# kernel = DotProduct() + WhiteKernel()\n",
    "# gpr = GaussianProcessRegressor(kernel,random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test)) # 0.632"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Default Kernel\n",
    "Bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 15 s\n",
    "\n",
    "# gpr = GaussianProcessRegressor(random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test)) # -0.806"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 RBF + ExpSineSquared\n",
    "Idea is that sequences are \"periodic\" data, and sequences repeat in groups. If we combine RBF and periodic kernel we could better model the data. Model wouldn't run due to LinAlgError:\n",
    "\n",
    "```\n",
    "LinAlgError: (\"The kernel, RBF(length_scale=1) + ExpSineSquared(length_scale=1, periodicity=1), is not returning a positive definite matrix. Try gradually increasing the 'alpha' parameter of your GaussianProcessRegressor estimator.\", '10-th leading minor of the array is not positive definite')\n",
    "```\n",
    "\n",
    "Attempted to modify alpha to fix issue, to no avail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from numpy.linalg import LinAlgError\n",
    "\n",
    "# kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) + ExpSineSquared(length_scale=1, periodicity=1)\n",
    "\n",
    "# for alpha in [1E-9,1E-8,1E-7,1E-6,1E-5,1E-4,1E-3,1E-2,1E-1,1E-0]:\n",
    "        \n",
    "# #     try:\n",
    "# #         gpr = GaussianProcessRegressor(kernel,random_state=seed, alpha=alpha)\n",
    "# #         gpr.fit(X_train, y_train)\n",
    "# #         print(alpha, gpr.score(X_test,y_test))  \n",
    "# #     except LinAlgError:\n",
    "# #         print(alpha, \"Error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 Matern\n",
    "Good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 2 min\n",
    "\n",
    "# kernel = Matern(length_scale=1.0, nu=1.5)\n",
    "\n",
    "# gpr = GaussianProcessRegressor(kernel,random_state=seed)\n",
    "# gpr.fit(X_train, y_train)\n",
    "# print(gpr.score(X_test,y_test)) # 0.687"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Active Learning model - Grid Search v1\n",
    "Experiments to test out various combinations to achieve $R^2 \\ge 0.6$ threshold.\n",
    "\n",
    "All experiments in this section use the following configurations:\n",
    "- Category: Committee\n",
    "- Learner: Gaussian Process\n",
    "- query_strategy: max_std_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?? Cookbook suggests \"put a product of SE kernels on those dimensions\" (I have 180 dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matern_details(kernel):\n",
    "    return [kernel,kernel.length_scale, kernel.nu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_details(kernel):\n",
    "    return [kernel, kernel.length_scale, kernel.length_scale_bounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rationalquadratic_details(kernel):\n",
    "    return [kernel, kernel.length_scale, kernel.alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_plus_white(kernel):\n",
    "    return [kernel, kernel.k1.length_scale, kernel.k2.noise_level]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Matern\n",
    "- 26 minutes with `2*2*10` Matern configurations at 100 queries - 2,5 learners\n",
    "- 3 hours 4 minutes with `2*2*10` Matern configurations at 100 queries - 10,20 learners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # results file\n",
    "# filename = 'data/gridsearch.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# row_prefix = ['Committee','Gaussian Process','max_std_sampling']\n",
    "# fields = ['category','learner','query_strategy','kernel','length_scale', 'nu', 'n_learners', 'n_initial','n_queries','r2']\n",
    "\n",
    "# # configs\n",
    "# kernels = [Matern(length_scale=i, nu=1.5) for i in np.linspace(0.5,1,2)]\n",
    "\n",
    "# n_learners = [2]\n",
    "# n_initials = [10]\n",
    "# n_queries = 1\n",
    "\n",
    "# # run process\n",
    "# gaussian_process_regressor_gs(kernels,n_learners,n_initials,X_train,y_train,X_test,y_test,n_queries,\n",
    "#                                         seed, filename, fields, row_prefix, matern_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # results file\n",
    "# filename = 'data/gridsearch.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# row_prefix = ['Committee','Gaussian Process','max_std_sampling']\n",
    "# fields = ['category','learner','query_strategy','kernel','length_scale', 'length_scale_bounds', 'n_learners', 'n_initial','n_queries','r2']\n",
    "\n",
    "# # configs\n",
    "# kernels = [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.linspace(0.38,0.418,2)]\n",
    "\n",
    "# n_learners = [2]\n",
    "# n_initials = [10]\n",
    "# n_queries = 1\n",
    "\n",
    "# # run process\n",
    "# gaussian_process_regressor_gs(kernels,n_learners,n_initials,X_train,y_train,X_test,y_test,n_queries,\n",
    "#                                         seed, filename, fields, row_prefix, rbf_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. RationalQuadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # results file\n",
    "# filename = 'data/gridsearch.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# row_prefix = ['Committee','Gaussian Process','max_std_sampling']\n",
    "# fields = ['category','learner','query_strategy','kernel','length_scale', 'alpha', 'n_learners', 'n_initial','n_queries','r2']\n",
    "\n",
    "# # configs\n",
    "# kernels = [RationalQuadratic(length_scale=i, alpha=j, length_scale_bounds=(1e-2, 1e3)) \n",
    "#            for i in np.linspace(0.5,10,2) \n",
    "#            for j in np.linspace(0.5,2,2)]\n",
    "\n",
    "# n_learners = [2]\n",
    "# n_initials = [10]\n",
    "# n_queries = 1\n",
    "\n",
    "# # run process\n",
    "# gaussian_process_regressor_gs(kernels,n_learners,n_initials,X_train,y_train,X_test,y_test,n_queries,\n",
    "#                                         seed, filename, fields, row_prefix, rationalquadratic_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. RBF + WhiteKernel random search\n",
    "Stopped halfway through because results weren't interesting. Adding noise doesn't improve score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # results file\n",
    "# filename = 'data/gridsearch.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# row_prefix = ['Committee','Gaussian Process','max_std_sampling']\n",
    "# fields = ['category','learner','query_strategy','kernel','rbf_length_scale', 'white_noise_scale', 'n_learners', 'n_initial','n_queries','r2']\n",
    "\n",
    "# # configs\n",
    "# kernels = [RBF(length_scale=0.45,length_scale_bounds=(1e-2, 1e3)) \\\n",
    "#            + WhiteKernel(noise_level=i, noise_level_bounds=(1e-10, 1e+1)) \n",
    "#            for i in np.random.uniform(low=0.1,high=1.0,size=20)]\n",
    "\n",
    "# n_learners = [10]\n",
    "# n_initials = [80]\n",
    "# n_queries = 100\n",
    "\n",
    "# # run process\n",
    "# gaussian_process_regressor_gs(kernels,n_learners,n_initials,X_train,y_train,X_test,y_test,n_queries,\n",
    "#                                         seed, filename, fields, row_prefix, rbf_plus_white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. RBF linear search wide\n",
    "Search for peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # results file\n",
    "# filename = 'data/gridsearch.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# row_prefix = ['Committee','Gaussian Process','max_std_sampling']\n",
    "# fields = ['category','learner','query_strategy','kernel','length_scale', 'length_scale_bounds', 'n_learners', 'n_initial','n_queries','r2']\n",
    "\n",
    "# # configs\n",
    "# kernels = [RBF(length_scale=i) for i in [1e-10,1e-5,1e-2,1e-1,1,1e1,100]]\n",
    "\n",
    "# n_learners = [10]\n",
    "# n_initials = [80]\n",
    "# n_queries = 100\n",
    "\n",
    "# # run process\n",
    "# gaussian_process_regressor_gs(kernels,n_learners,n_initials,X_train,y_train,X_test,y_test,n_queries,\n",
    "#                                         seed, filename, fields, row_prefix, rbf_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. RBF linear search narrow\n",
    "Search near current peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 1 hour\n",
    "\n",
    "# # results file\n",
    "# filename = 'data/gridsearch.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# row_prefix = ['Committee','Gaussian Process','max_std_sampling']\n",
    "# fields = ['category','learner','query_strategy','kernel','length_scale', 'length_scale_bounds', 'n_learners', 'n_initial','n_queries','r2']\n",
    "\n",
    "# # configs\n",
    "# kernels = [RBF(length_scale=i) for i in np.linspace(0.1,1,10)] \\\n",
    "#         + [RBF(length_scale=i) for i in np.linspace(1,10,10)]\n",
    "\n",
    "# n_learners = [10]\n",
    "# n_initials = [80]\n",
    "# n_queries = 100\n",
    "\n",
    "# # run process\n",
    "# gaussian_process_regressor_gs(kernels,n_learners,n_initials,X_train,y_train,X_test,y_test,n_queries,\n",
    "#                                         seed, filename, fields, row_prefix, rbf_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. RBF linear search narrow 2\n",
    "Search near current peaks. Skipped fifth run due to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # results file\n",
    "# filename = 'data/gridsearch.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# row_prefix = ['Committee','Gaussian Process','max_std_sampling']\n",
    "# fields = ['category','learner','query_strategy','kernel','length_scale', 'length_scale_bounds', 'n_learners', 'n_initial','n_queries','r2']\n",
    "\n",
    "# # configs\n",
    "# kernels = [RBF(length_scale=i) for i in np.linspace(0.4,7,40)] \\\n",
    "#         + [RBF(length_scale=i) for i in np.linspace(0.4,7,40)] \\\n",
    "#         + [RBF(length_scale=i) for i in np.linspace(0.4,7,40)] \\\n",
    "#         + [RBF(length_scale=i) for i in np.linspace(0.4,7,40)] \\\n",
    "#         + [RBF(length_scale=i) for i in np.linspace(0.4,7,40)]\n",
    "\n",
    "# n_learners = [10]\n",
    "# n_initials = [80]\n",
    "# n_queries = 100\n",
    "\n",
    "# # run process\n",
    "# gaussian_process_regressor_gs(kernels,n_learners,n_initials,X_train,y_train,X_test,y_test,n_queries,\n",
    "#                                         seed, filename, fields, row_prefix, rbf_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8. RBF linear search narrow 3\n",
    "Search near current peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 3h 4 min\n",
    "\n",
    "# # results file\n",
    "# filename = 'data/gridsearch.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# row_prefix = ['Committee','Gaussian Process','max_std_sampling']\n",
    "# fields = ['category','learner','query_strategy','kernel','length_scale', 'length_scale_bounds', 'n_learners', 'n_initial','n_queries','r2']\n",
    "\n",
    "# # configs\n",
    "# kernels = [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.linspace(0.45,0.55,10)] \\\n",
    "#         + [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.linspace(0.7,0.8,10)] \\\n",
    "#         + [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.linspace(2.4,3.0,10)] \\\n",
    "#         + [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.linspace(3.7,4.0,10)] \\\n",
    "#         + [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.linspace(4.8,5.2,10)]  \n",
    "\n",
    "# n_learners = [10]\n",
    "# n_initials = [80]\n",
    "# n_queries = 100\n",
    "\n",
    "# # run process\n",
    "# gaussian_process_regressor_gs(kernels,n_learners,n_initials,X_train,y_train,X_test,y_test,n_queries,\n",
    "#                                         seed, filename, fields, row_prefix, rbf_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9. RBF random search narrow\n",
    "Randomized points near peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF(length_scale=2.76)|10|80|100|0.5635222023115654\n",
      "RBF(length_scale=2.51)|10|80|100|0.5337165452605679\n",
      "RBF(length_scale=2.47)|10|80|100|0.5489614420553026\n",
      "RBF(length_scale=2.94)|10|80|100|0.5283697583584003\n",
      "RBF(length_scale=2.65)|10|80|100|0.5344300885630899\n",
      "RBF(length_scale=2.41)|10|80|100|0.5526588906310574\n",
      "RBF(length_scale=2.99)|10|80|100|0.5503690594715509\n",
      "RBF(length_scale=2.47)|10|80|100|0.5485406059990521\n",
      "RBF(length_scale=2.62)|10|80|100|0.5242808318628994\n",
      "RBF(length_scale=2.41)|10|80|100|0.5605198240938523\n",
      "RBF(length_scale=2.41)|10|80|100|0.5320978421020564\n",
      "RBF(length_scale=2.98)|10|80|100|0.5519891745018656\n",
      "RBF(length_scale=2.81)|10|80|100|0.5440711891091994\n",
      "RBF(length_scale=2.76)|10|80|100|0.5362017242590282\n",
      "RBF(length_scale=2.78)|10|80|100|0.5401868832042537\n",
      "RBF(length_scale=2.62)|10|80|100|0.5445414171042621\n",
      "RBF(length_scale=2.6)|10|80|100|0.5394760369539029\n",
      "RBF(length_scale=2.42)|10|80|100|0.5517369385722448\n",
      "RBF(length_scale=2.74)|10|80|100|0.541609830847074\n",
      "RBF(length_scale=2.88)|10|80|100|0.5341648418884971\n",
      "RBF(length_scale=3.84)|10|80|100|0.5396870144289574\n",
      "RBF(length_scale=3.99)|10|80|100|0.5526126040150044\n",
      "RBF(length_scale=3.84)|10|80|100|0.5424731577178122\n",
      "RBF(length_scale=3.87)|10|80|100|0.5508497400618562\n",
      "RBF(length_scale=3.99)|10|80|100|0.5554851486957115\n",
      "RBF(length_scale=3.82)|10|80|100|0.5067504310631961\n",
      "RBF(length_scale=3.81)|10|80|100|0.525463562452511\n",
      "RBF(length_scale=3.84)|10|80|100|0.548064624288914\n",
      "RBF(length_scale=3.95)|10|80|100|0.5535287257429078\n",
      "RBF(length_scale=3.85)|10|80|100|0.53369229307875\n",
      "RBF(length_scale=3.83)|10|80|100|0.5178615166747456\n",
      "RBF(length_scale=3.85)|10|80|100|0.5444842428680057\n",
      "RBF(length_scale=3.92)|10|80|100|0.5269075886672376\n",
      "RBF(length_scale=3.97)|10|80|100|0.547340066482843\n",
      "RBF(length_scale=3.88)|10|80|100|0.5545219851359329\n",
      "RBF(length_scale=3.92)|10|80|100|0.5407106812947429\n",
      "RBF(length_scale=3.88)|10|80|100|0.5527072427073279\n",
      "RBF(length_scale=3.85)|10|80|100|0.5511933719768094\n",
      "RBF(length_scale=3.8)|10|80|100|0.5383009694995269\n",
      "RBF(length_scale=3.92)|10|80|100|0.527488526553963\n",
      "RBF(length_scale=4.85)|10|80|100|0.5193246991941508\n",
      "RBF(length_scale=4.88)|10|80|100|0.5518778324140645\n",
      "RBF(length_scale=4.9)|10|80|100|0.5387906537144068\n",
      "RBF(length_scale=4.84)|10|80|100|0.537845890953665\n",
      "RBF(length_scale=4.84)|10|80|100|0.5530491853495119\n",
      "RBF(length_scale=4.97)|10|80|100|0.5275277330860972\n",
      "RBF(length_scale=4.97)|10|80|100|0.5339664495501901\n",
      "RBF(length_scale=4.98)|10|80|100|0.5262490576672092\n",
      "RBF(length_scale=4.82)|10|80|100|0.5476543553767147\n",
      "RBF(length_scale=4.88)|10|80|100|0.5197909694718688\n",
      "RBF(length_scale=4.93)|10|80|100|0.5317174841048432\n",
      "RBF(length_scale=4.83)|10|80|100|0.5440211476873549\n",
      "RBF(length_scale=4.98)|10|80|100|0.5392934667087479\n",
      "RBF(length_scale=4.94)|10|80|100|0.5586459871021117\n",
      "RBF(length_scale=4.98)|10|80|100|0.5669607515832844\n",
      "RBF(length_scale=5)|10|80|100|0.5436019873282792\n",
      "RBF(length_scale=4.87)|10|80|100|0.5445673156768844\n",
      "RBF(length_scale=4.92)|10|80|100|0.5546922409490376\n",
      "RBF(length_scale=4.89)|10|80|100|0.5450999479791014\n",
      "RBF(length_scale=4.89)|10|80|100|0.5430872928878181\n",
      "RBF(length_scale=0.49)|10|80|100|0.5508332728762673\n",
      "RBF(length_scale=0.496)|10|80|100|0.5376860282817212\n",
      "RBF(length_scale=0.499)|10|80|100|0.5214045344649225\n",
      "RBF(length_scale=0.499)|10|80|100|0.5414194724738127\n",
      "RBF(length_scale=0.504)|10|80|100|0.5222151971477813\n",
      "RBF(length_scale=0.505)|10|80|100|0.5450660153326579\n",
      "RBF(length_scale=0.499)|10|80|100|0.5016055287469946\n",
      "RBF(length_scale=0.497)|10|80|100|0.5203548255802337\n",
      "RBF(length_scale=0.495)|10|80|100|0.5336250321828186\n",
      "RBF(length_scale=0.504)|10|80|100|0.5398539779520057\n",
      "RBF(length_scale=0.507)|10|80|100|0.5294951523896708\n",
      "RBF(length_scale=0.498)|10|80|100|0.506283863949671\n",
      "RBF(length_scale=0.503)|10|80|100|0.5311357458370198\n",
      "RBF(length_scale=0.495)|10|80|100|0.535234377540703\n",
      "RBF(length_scale=0.503)|10|80|100|0.5454330280877859\n",
      "RBF(length_scale=0.509)|10|80|100|0.5264395622802848\n",
      "RBF(length_scale=0.499)|10|80|100|0.552594615261105\n",
      "RBF(length_scale=0.506)|10|80|100|0.5508188080328154\n",
      "RBF(length_scale=0.492)|10|80|100|0.532697350579391\n",
      "RBF(length_scale=0.503)|10|80|100|0.5380607587080992\n",
      "CPU times: user 18h 11min 2s, sys: 11min 9s, total: 18h 22min 11s\n",
      "Wall time: 4h 41min 28s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# # results file\n",
    "# filename = 'data/gridsearch.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "\n",
    "# ex_id = ['3.9']\n",
    "# row_prefix = ex_id + ['Committee','Gaussian Process','max_std_sampling']\n",
    "# fields = ['experiment','category','learner','query_strategy','kernel','length_scale', 'length_scale_bounds', 'n_learners', 'n_initial','n_queries','r2']\n",
    "\n",
    "# # configs\n",
    "# kernels = [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.random.uniform(low=2.4,high=3.0,size=20)] \\\n",
    "#         + [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.random.uniform(low=3.8,high=4.0,size=20)] \\\n",
    "#         + [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.random.uniform(low=4.8,high=5.0,size=20)] \\\n",
    "#         + [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3)) for i in np.random.uniform(low=0.49,high=0.51,size=20)]\n",
    "\n",
    "# n_learners = [10]\n",
    "# n_initials = [80]\n",
    "# n_queries = 100\n",
    "\n",
    "# # run process\n",
    "# gs.grid_search_1(kernels,n_learners,n_initials,X_train,y_train,X_test,y_test,n_queries,\n",
    "#                                         seed, filename, fields, row_prefix, rbf_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10. RBF best points\n",
    "Checking rounded values near the highest R2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF(length_scale=2.76)|10|80|100|0.5635222023115654\n",
      "RBF(length_scale=2.51)|10|80|100|0.5337165452605679\n",
      "RBF(length_scale=2.47)|10|80|100|0.5489614420553026\n",
      "RBF(length_scale=2.94)|10|80|100|0.5283697583584003\n",
      "RBF(length_scale=2.65)|10|80|100|0.5344300885630899\n",
      "RBF(length_scale=2.41)|10|80|100|0.5526588906310574\n",
      "RBF(length_scale=2.99)|10|80|100|0.5503690594715509\n",
      "RBF(length_scale=2.47)|10|80|100|0.5485406059990521\n",
      "RBF(length_scale=2.62)|10|80|100|0.5242808318628994\n",
      "RBF(length_scale=2.41)|10|80|100|0.5605198240938523\n",
      "RBF(length_scale=2.41)|10|80|100|0.5320978421020564\n",
      "RBF(length_scale=2.98)|10|80|100|0.5519891745018656\n",
      "RBF(length_scale=2.81)|10|80|100|0.5440711891091994\n",
      "RBF(length_scale=2.76)|10|80|100|0.5362017242590282\n",
      "RBF(length_scale=2.78)|10|80|100|0.5401868832042537\n",
      "RBF(length_scale=2.62)|10|80|100|0.5445414171042621\n",
      "RBF(length_scale=2.6)|10|80|100|0.5394760369539029\n",
      "RBF(length_scale=2.42)|10|80|100|0.5517369385722448\n",
      "RBF(length_scale=2.74)|10|80|100|0.541609830847074\n",
      "RBF(length_scale=2.88)|10|80|100|0.5341648418884971\n",
      "RBF(length_scale=3.84)|10|80|100|0.5396870144289574\n",
      "RBF(length_scale=3.99)|10|80|100|0.5526126040150044\n",
      "RBF(length_scale=3.84)|10|80|100|0.5424731577178122\n",
      "RBF(length_scale=3.87)|10|80|100|0.5508497400618562\n",
      "RBF(length_scale=3.99)|10|80|100|0.5554851486957115\n",
      "RBF(length_scale=3.82)|10|80|100|0.5067504310631961\n",
      "RBF(length_scale=3.81)|10|80|100|0.525463562452511\n",
      "RBF(length_scale=3.84)|10|80|100|0.548064624288914\n",
      "RBF(length_scale=3.95)|10|80|100|0.5535287257429078\n",
      "RBF(length_scale=3.85)|10|80|100|0.53369229307875\n",
      "RBF(length_scale=3.83)|10|80|100|0.5178615166747456\n",
      "RBF(length_scale=3.85)|10|80|100|0.5444842428680057\n",
      "RBF(length_scale=3.92)|10|80|100|0.5269075886672376\n",
      "RBF(length_scale=3.97)|10|80|100|0.547340066482843\n",
      "RBF(length_scale=3.88)|10|80|100|0.5545219851359329\n",
      "RBF(length_scale=3.92)|10|80|100|0.5407106812947429\n",
      "RBF(length_scale=3.88)|10|80|100|0.5527072427073279\n",
      "RBF(length_scale=3.85)|10|80|100|0.5511933719768094\n",
      "RBF(length_scale=3.8)|10|80|100|0.5383009694995269\n",
      "RBF(length_scale=3.92)|10|80|100|0.527488526553963\n",
      "RBF(length_scale=4.85)|10|80|100|0.5193246991941508\n",
      "RBF(length_scale=4.88)|10|80|100|0.5518778324140645\n",
      "RBF(length_scale=4.9)|10|80|100|0.5387906537144068\n",
      "RBF(length_scale=4.84)|10|80|100|0.537845890953665\n",
      "RBF(length_scale=4.84)|10|80|100|0.5530491853495119\n",
      "RBF(length_scale=4.97)|10|80|100|0.5275277330860972\n",
      "RBF(length_scale=4.97)|10|80|100|0.5339664495501901\n",
      "RBF(length_scale=4.98)|10|80|100|0.5262490576672092\n",
      "RBF(length_scale=4.82)|10|80|100|0.5476543553767147\n",
      "RBF(length_scale=4.88)|10|80|100|0.5197909694718688\n",
      "RBF(length_scale=4.93)|10|80|100|0.5317174841048432\n",
      "RBF(length_scale=4.83)|10|80|100|0.5440211476873549\n",
      "RBF(length_scale=4.98)|10|80|100|0.5392934667087479\n",
      "RBF(length_scale=4.94)|10|80|100|0.5586459871021117\n",
      "RBF(length_scale=4.98)|10|80|100|0.5669607515832844\n",
      "RBF(length_scale=5)|10|80|100|0.5436019873282792\n",
      "RBF(length_scale=4.87)|10|80|100|0.5445673156768844\n",
      "RBF(length_scale=4.92)|10|80|100|0.5546922409490376\n",
      "RBF(length_scale=4.89)|10|80|100|0.5450999479791014\n",
      "RBF(length_scale=4.89)|10|80|100|0.5430872928878181\n",
      "RBF(length_scale=0.49)|10|80|100|0.5508332728762673\n",
      "RBF(length_scale=0.496)|10|80|100|0.5376860282817212\n",
      "RBF(length_scale=0.499)|10|80|100|0.5214045344649225\n",
      "RBF(length_scale=0.499)|10|80|100|0.5414194724738127\n",
      "RBF(length_scale=0.504)|10|80|100|0.5222151971477813\n",
      "RBF(length_scale=0.505)|10|80|100|0.5450660153326579\n",
      "RBF(length_scale=0.499)|10|80|100|0.5016055287469946\n",
      "RBF(length_scale=0.497)|10|80|100|0.5203548255802337\n",
      "RBF(length_scale=0.495)|10|80|100|0.5336250321828186\n",
      "RBF(length_scale=0.504)|10|80|100|0.5398539779520057\n",
      "RBF(length_scale=0.507)|10|80|100|0.5294951523896708\n",
      "RBF(length_scale=0.498)|10|80|100|0.506283863949671\n",
      "RBF(length_scale=0.503)|10|80|100|0.5311357458370198\n",
      "RBF(length_scale=0.495)|10|80|100|0.535234377540703\n",
      "RBF(length_scale=0.503)|10|80|100|0.5454330280877859\n",
      "RBF(length_scale=0.509)|10|80|100|0.5264395622802848\n",
      "RBF(length_scale=0.499)|10|80|100|0.552594615261105\n",
      "RBF(length_scale=0.506)|10|80|100|0.5508188080328154\n",
      "RBF(length_scale=0.492)|10|80|100|0.532697350579391\n",
      "RBF(length_scale=0.503)|10|80|100|0.5380607587080992\n",
      "CPU times: user 18h 11min 2s, sys: 11min 9s, total: 18h 22min 11s\n",
      "Wall time: 4h 41min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# results file\n",
    "filename = 'data/gridsearch.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "\n",
    "ex_id = ['3.9']\n",
    "row_prefix = ex_id + ['Committee','Gaussian Process','max_std_sampling']\n",
    "fields = ['experiment','category','learner','query_strategy','kernel','length_scale', 'length_scale_bounds', 'n_learners', 'n_initial','n_queries','r2']\n",
    "\n",
    "# configs\n",
    "kernels = [RBF(length_scale=i,length_scale_bounds=(1e-2, 1e3))\n",
    "           for i in [0.500,0.738,1.923,3.785,5.985,2.769,2.760,2.412,4.983]]\n",
    "\n",
    "n_learners = [10]\n",
    "n_initials = [80]\n",
    "n_queries = 100\n",
    "\n",
    "# run process\n",
    "gs.grid_search_1(kernels,n_learners,n_initials,X_train,y_train,X_test,y_test,n_queries,\n",
    "                                        seed, filename, fields, row_prefix, rbf_details)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
